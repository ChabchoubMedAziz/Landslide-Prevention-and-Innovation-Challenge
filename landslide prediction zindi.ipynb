{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a name = \"Libraries\"></a>\n## 1. Import relevant libraries","metadata":{"id":"Sl-lBcUwJZX2"}},{"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import f1_score\npd.set_option('display.max_columns', None)\nimport warnings\nfrom sklearn.model_selection import KFold,StratifiedKFold,RepeatedStratifiedKFold,train_test_split\nimport lightgbm as lgb \nimport xgboost as xgb\n\nseed = 111\nfrom scipy import stats as st\n\nwarnings.filterwarnings('ignore')","metadata":{"id":"AGkN_YDYrXeS","execution":{"iopub.status.busy":"2022-09-28T21:49:42.021498Z","iopub.execute_input":"2022-09-28T21:49:42.021926Z","iopub.status.idle":"2022-09-28T21:49:43.596923Z","shell.execute_reply.started":"2022-09-28T21:49:42.021889Z","shell.execute_reply":"2022-09-28T21:49:43.595952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name = \"Load\"></a>\n## 2. Load files","metadata":{"id":"31jrsc4hJdw1"}},{"cell_type":"code","source":"# Read files to pandas dataframes\ntrain = pd.read_csv('../input/landslide/Train.csv')\ntest = pd.read_csv('../input/landslide/Test.csv')\nsample_submission = pd.read_csv('../input/landslide/SampleSubmission.csv')\nsample=test.Sample_ID","metadata":{"id":"pK406xHWrk3r","execution":{"iopub.status.busy":"2022-09-28T21:49:43.598717Z","iopub.execute_input":"2022-09-28T21:49:43.599029Z","iopub.status.idle":"2022-09-28T21:49:44.552401Z","shell.execute_reply.started":"2022-09-28T21:49:43.599002Z","shell.execute_reply":"2022-09-28T21:49:44.551044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop('Sample_ID',axis=1,inplace=True)\ntest.drop('Sample_ID',axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T21:49:44.553976Z","iopub.execute_input":"2022-09-28T21:49:44.554310Z","iopub.status.idle":"2022-09-28T21:49:44.575304Z","shell.execute_reply.started":"2022-09-28T21:49:44.554280Z","shell.execute_reply":"2022-09-28T21:49:44.574114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name = \"Preview\"></a>\n## 3. Feature Engineer","metadata":{"id":"yv67GA1KJgiA"}},{"cell_type":"code","source":"df=pd.DataFrame()\nfor i in ['elevation', 'geology', 'lsfactor', 'placurv', 'procurv', 'sdoif', 'slope', 'twi', 'aspect']:\n  train[i] = train[[x for x in train.columns if i in x]].mean(axis = 1)\n  train[i+'1'] = train[[x for x in train.columns if i in x]].std(axis = 1)\n  train[i+'4'] = train[[x for x in train.columns if i in x]].median(axis = 1)\n  train[i+'5'] = train[[x for x in train.columns if i in x]].var(axis = 1)\n  train[i+'6'] = train[[x for x in train.columns if i in x]].sum(axis = 1)\n  train[i+'7'] = train[[x for x in train.columns if i in x]].max(axis = 1)\n  train[i+'8'] = train[[x for x in train.columns if i in x]].min(axis = 1)\n\ntrain.head()","metadata":{"id":"Cbrn7oUtK2_v","outputId":"0e60c74c-05e7-437f-ddda-f02ff220fbf6","execution":{"iopub.status.busy":"2022-09-28T21:49:44.577056Z","iopub.execute_input":"2022-09-28T21:49:44.577640Z","iopub.status.idle":"2022-09-28T21:49:45.952167Z","shell.execute_reply.started":"2022-09-28T21:49:44.577595Z","shell.execute_reply":"2022-09-28T21:49:45.950403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in ['elevation', 'geology', 'lsfactor', 'placurv', 'procurv', 'sdoif', 'slope', 'twi', 'aspect']:\n  test[i] = test[[x for x in test.columns if i in x]].mean(axis = 1)\n  test[i+'1'] = test[[x for x in test.columns if i in x]].std(axis = 1)\n  test[i+'4'] = test[[x for x in test.columns if i in x]].median(axis = 1)\n  test[i+'5'] = test[[x for x in test.columns if i in x]].var(axis = 1)\n  test[i+'6'] = test[[x for x in test.columns if i in x]].sum(axis = 1)\n  test[i+'7'] = test[[x for x in test.columns if i in x]].max(axis = 1)\n  test[i+'8'] = test[[x for x in test.columns if i in x]].min(axis = 1)\n\n\n\n\ntest.head()","metadata":{"id":"hjUsq6ghMtVt","outputId":"a9fd7000-04d6-43fe-8cad-410022eae843","execution":{"iopub.status.busy":"2022-09-28T21:49:45.956244Z","iopub.execute_input":"2022-09-28T21:49:45.956722Z","iopub.status.idle":"2022-09-28T21:49:46.589486Z","shell.execute_reply.started":"2022-09-28T21:49:45.956675Z","shell.execute_reply":"2022-09-28T21:49:46.588413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset imbalanced for that SMOTE is a good hack","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE, ADASYN\n\ny = train.Label\nX=train.drop('Label',axis=1)\n\nX_resampled, y_resampled = SMOTE().fit_resample(X, y)","metadata":{"id":"4w9rZSXdrk0o","outputId":"ba4a7550-1898-4904-ff3f-984ea75c0f9e","execution":{"iopub.status.busy":"2022-09-28T21:49:46.590713Z","iopub.execute_input":"2022-09-28T21:49:46.591042Z","iopub.status.idle":"2022-09-28T21:49:47.301671Z","shell.execute_reply.started":"2022-09-28T21:49:46.591013Z","shell.execute_reply":"2022-09-28T21:49:47.300572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name = \"Model\"></a>\n## 9. Model training using 10 StratifiedKfold with XGBClassifier","metadata":{"id":"GbN3sDZxJHVb"}},{"cell_type":"code","source":"%%time\ntess = test\n\n# Stratified Validation\nfolds = StratifiedKFold(n_splits = 10)\n\n# Dataframe to store feature importance\nfeature_importance_df = pd.DataFrame()\n\n# Lists to store predictions and losses\nseason_predictions_xgb = []\nlosses = []\nfor i,( train_index, test_index) in enumerate(folds.split(X_resampled, y_resampled)):\n  X_train, X_test, y_train, y_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index], y_resampled[train_index], y_resampled[test_index]\n\n  # Instantiate model\n  model1 = xgb.XGBClassifier(\n                             n_estimators = 5000,\n                             colsample_bytree=0.7,\n                             subsample =0.6,\n                             seed=11,\n                             random_state = 11,\n                           \n                            )\n\n  # Train model\n  model1.fit(X_train, y_train,\n            eval_set=[(X_test, y_test)],\n            early_stopping_rounds=400,\n            verbose = 1000,\n)\n\n  # Make predictions\n  preds = model1.predict_proba(tess)\n  y_pred = model1.predict_proba(X_test)\n\n  # Append predictions and losses\n  season_predictions_xgb.append(preds)\n  loss = f1_score(y_test, model1.predict(X_test))\n\n  # Append feature importance per fold\n  #fold_importance_df = pd.DataFrame({'feature': X_train.columns.tolist(), 'importance': model.feature_importances_})\n  #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n  # Print loss\n  print(f'{i+1}:  {loss}\\n')\n  losses.append(loss)\n\nprint(f'Mean Loss: {np.mean(losses)}')","metadata":{"execution":{"iopub.status.busy":"2022-09-28T21:49:47.303050Z","iopub.execute_input":"2022-09-28T21:49:47.303403Z","iopub.status.idle":"2022-09-28T22:03:43.456022Z","shell.execute_reply.started":"2022-09-28T21:49:47.303372Z","shell.execute_reply":"2022-09-28T22:03:43.455091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting the mean of probs for the 10 Folds","metadata":{}},{"cell_type":"code","source":"xgb_preds = np.mean(season_predictions_xgb,axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T22:03:43.457569Z","iopub.execute_input":"2022-09-28T22:03:43.458140Z","iopub.status.idle":"2022-09-28T22:03:43.464034Z","shell.execute_reply.started":"2022-09-28T22:03:43.458104Z","shell.execute_reply":"2022-09-28T22:03:43.463083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_df = test\npreds = [1 if x >= 0.3 else 0 for x in np.mean(season_predictions_xgb, axis = 0)[:, 1]]\nsub_file = pd.DataFrame({'Sample_ID': sample, 'Label': preds})\n# Check the distribution of your predictions\nsns.countplot(x = sub_file.Label)\nplt.title('Predicted Variable Distribution');","metadata":{"execution":{"iopub.status.busy":"2022-09-28T22:03:43.465405Z","iopub.execute_input":"2022-09-28T22:03:43.466339Z","iopub.status.idle":"2022-09-28T22:03:43.697571Z","shell.execute_reply.started":"2022-09-28T22:03:43.466306Z","shell.execute_reply":"2022-09-28T22:03:43.696462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 10. Model training using 10 StratifiedKfold with LGBMClassifier","metadata":{}},{"cell_type":"code","source":"%%time\ntess = test\n\n# Stratified Validation\nfolds = StratifiedKFold(n_splits = 10)\n\n# Dataframe to store feature importance\nfeature_importance_df = pd.DataFrame()\n\n# Lists to store predictions and losses\nseason_predictions_lgb = []\nlosses = []\nfor i,( train_index, test_index) in enumerate(folds.split(X_resampled, y_resampled)):\n    X_train, X_test, y_train, y_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index], y_resampled[train_index], y_resampled[test_index]\n\n  # Instantiate model\n    model2 = lgb.LGBMClassifier(\n    boosting_type= \"gbdt\",\n    colsample_bytree= 0.9,\n    learning_rate = 0.05,\n    n_estimators = 3000,\n    objective ='binary',\n    random_state = 2022,)\n\n  # Train model\n    model2.fit(X_train, y_train,\n            eval_set=[(X_test, y_test)],\n            early_stopping_rounds=400,\n            verbose = 1000,\n)\n\n  # Make predictions\n    preds = model2.predict_proba(tess)\n    y_pred = model2.predict_proba(X_test)\n\n  # Append predictions and losses\n    season_predictions_lgb.append(preds)\n    loss = f1_score(y_test, model2.predict(X_test))\n\n  # Append feature importance per fold\n    #fold_importance_df = pd.DataFrame({'feature': X_train.columns.tolist(), 'importance': model.feature_importances_})\n    #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n  # Print loss\n    print(f'{i+1}:  {loss}\\n')\n    losses.append(loss)\n\nprint(f'Mean Loss: {np.mean(losses)}')","metadata":{"execution":{"iopub.status.busy":"2022-09-28T22:03:43.699058Z","iopub.execute_input":"2022-09-28T22:03:43.699907Z","iopub.status.idle":"2022-09-28T22:08:50.920719Z","shell.execute_reply.started":"2022-09-28T22:03:43.699865Z","shell.execute_reply":"2022-09-28T22:08:50.919700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting the mean of probs for the 10 Folds","metadata":{}},{"cell_type":"code","source":"lgb_preds = np.mean(season_predictions_lgb,axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-09-28T22:08:50.925271Z","iopub.execute_input":"2022-09-28T22:08:50.928815Z","iopub.status.idle":"2022-09-28T22:08:50.934553Z","shell.execute_reply.started":"2022-09-28T22:08:50.928776Z","shell.execute_reply":"2022-09-28T22:08:50.933726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = [1 if x >= 0.28 else 0 for x in np.mean(season_predictions_lgb, axis = 0)[:, 1]]\nsub_file = pd.DataFrame({'Sample_ID': sample, 'Label': preds})\n# Check the distribution of your predictions\nsns.countplot(x = sub_file.Label)\nplt.title('Predicted Variable Distribution');","metadata":{"execution":{"iopub.status.busy":"2022-09-28T22:08:50.936027Z","iopub.execute_input":"2022-09-28T22:08:50.936399Z","iopub.status.idle":"2022-09-28T22:08:51.138410Z","shell.execute_reply.started":"2022-09-28T22:08:50.936370Z","shell.execute_reply":"2022-09-28T22:08:51.137572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 11. Ensemble both preds of XGB and LightGBM and create a submit file","metadata":{}},{"cell_type":"code","source":"\nlast_pred=lgb_preds*0.5 +  xgb_preds*0.5\npred=[1 if x >= 0.3 else 0 for x in last_pred[:, 1]]\nsub_file = pd.DataFrame({'Sample_ID': sample, 'Label': pred})\n# Check the distribution of your predictions\nsns.countplot(x = sub_file.Label)\nplt.title('Predicted Variable Distribution');\n\n# Create a csv file and upload to zindi \nsub_file.to_csv('Baseline.csv', index = False)\nsub_file.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-28T22:16:29.682714Z","iopub.execute_input":"2022-09-28T22:16:29.683148Z","iopub.status.idle":"2022-09-28T22:16:29.888094Z","shell.execute_reply.started":"2022-09-28T22:16:29.683117Z","shell.execute_reply":"2022-09-28T22:16:29.887180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name = \"Tips\"></a>\n## 12. Tips to improve model performance\n - Use cross-validation techniques\n - Feature engineering\n - Handle the class imbalance of the target variable\n - Try different modelling techniques - Stacking classifier, Voting classifiers, ensembling...\n - Data transformations\n - Feature Selection techniques such as RFE, Tree-based feature importance...\n - Domain Knowledge, do research on how the provided features affect landslides, soil topology...","metadata":{"id":"2Md0cnDIJwiy"}},{"cell_type":"markdown","source":"#                       ::Upvote will be very appreciated ðŸ˜Š\n\n\n","metadata":{"id":"3io5PEySK5x0"}}]}